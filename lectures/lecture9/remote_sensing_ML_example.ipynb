{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "remote_sensing_ML_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzMMRjJYbuU9uBDhsNxevm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rg-smith/remote_sensing_course/blob/main/lectures/lecture9/remote_sensing_ML_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmq8S5fDutSs"
      },
      "source": [
        "### In-class assignment: Machine Learning with Python\n",
        "\n",
        "In this assignment, we will repeat some of the exercises from Lab 10, but in python. You will see how with python, we can see what the model is doing with more detail than the simplified version in ArcMap.\n",
        "\n",
        "The study area is the same as lab 10: the flooded region surrounding Omaha, Nebraska following the Spring 2019 floods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj6jQiZGWRlx"
      },
      "source": [
        "###Part 1: Run through the machine learning model with an existing shapefile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1gFsnwbWWEp"
      },
      "source": [
        "First, we will install the required packages: rasterio and geopandas. This is done outside of python (the ! character runs from the command line)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVAWIcfud5t"
      },
      "source": [
        "!pip install rasterio geopandas\n",
        "!git clone https://github.com/rg-smith/remote_sensing_course.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rBnJLsavXB5"
      },
      "source": [
        "With the required packages installed, we will now load them as well as other packages that are installed automatically with Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsoY2F1JuXdw"
      },
      "source": [
        "import rasterio\n",
        "import geopandas\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from rasterio.plot import show\n",
        "from rasterio.mask import mask\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_raster_band(raster,band,ax=None):\n",
        "  if ax==None:\n",
        "    plt.imshow(r.read(band),vmin=np.percentile(r.read(band),1),vmax=np.percentile(r.read(band),99));plt.colorbar()\n",
        "    plt.xlabel('Easting, m')\n",
        "    plt.ylabel('Northing, m')\n",
        "    show(r.read(band),transform=r.transform,vmin=np.percentile(r.read(band),1),vmax=np.percentile(r.read(band),99))\n",
        "  else:\n",
        "    show(r.read(band),transform=r.transform,vmin=np.percentile(r.read(band),1),vmax=np.percentile(r.read(band),99),ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtMzaNpKwLh5"
      },
      "source": [
        "Now, we will load in the raster. We'll use the python package 'rasterio'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVS4usAwzHM6"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "r=rasterio.open('remote_sensing_course/lectures/lecture9/20190316_compressed_100m.tif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abh0PEQ-NFE0"
      },
      "source": [
        "Next, we'll plot the raster. Plot different bands by replacing 'band' with a number, 1 through 8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKHtOH5DNLBL"
      },
      "source": [
        "band = <enter band number> \n",
        "plot_raster_band(r,band)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M5rilRS2pNM"
      },
      "source": [
        "Now we will plot a histogram, which shows the number of pixels with a specific value (DN) for a range of different values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZAPnAe_EZKZ"
      },
      "source": [
        "rasterio.plot.show_hist(r,bins=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6vXdu3VGjLh"
      },
      "source": [
        "Now we will load some training data. This is a shapefile similar to the one you created in Lab 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weYL9syoFSar"
      },
      "source": [
        "shapefile_name = 'remote_sensing_course/lectures/lecture9/training_data.shp'\n",
        "shp=geopandas.read_file(shapefile_name)\n",
        "print(shp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldLj0jo_HQHj"
      },
      "source": [
        "Now plot this shapefile with a few different bands from the Landsat 8 image. As previously, change the 'enter band number here' to a band number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NemIj30ZFqjz"
      },
      "source": [
        "fig,ax=plt.subplots()\n",
        "\n",
        "band = <enter band number here>\n",
        "\n",
        "plot_raster_band(r,band,ax)\n",
        "shp.plot(ax=ax,facecolor='none',edgecolor='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYbsCa4r5Cpd"
      },
      "source": [
        "Now, we will prepare the training data by putting it in a format that is easy for python to build a model with. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2QFeV_Y7PR6"
      },
      "source": [
        "classes = np.unique(shp['Classname'])\n",
        "classvals = np.unique(shp['Classvalue'])\n",
        "print(classes)\n",
        "\n",
        "for kk in range(len(classes)):\n",
        "  class_ = classes[kk]\n",
        "  shp_filt=shp['Classname']==class_\n",
        "  print(shp[shp_filt])\n",
        "  r_mask,gtr=mask(r,shp['geometry'][shp_filt],crop=True,nodata=0)\n",
        "  if kk==0:\n",
        "    dat_train=r_mask.reshape(8,-1)\n",
        "    filt=dat_train[0,:]>0\n",
        "    dat_train=dat_train[:,filt].transpose()\n",
        "    dat_train=np.hstack((dat_train,kk*np.ones((dat_train.shape[0],1))))\n",
        "  else:\n",
        "    dat=r_mask.reshape(8,-1)\n",
        "    filt=dat[0,:]>0\n",
        "    dat=dat[:,filt].transpose()\n",
        "    dat=np.hstack((dat,kk*np.ones((dat.shape[0],1))))\n",
        "    dat_train=np.vstack((dat_train,dat))\n",
        "\n",
        "np.random.seed(0)\n",
        "filt = np.random.uniform(size=(dat_train.shape[0]))>0.25 # make a filter that randomly selects 75% of the data\n",
        "\n",
        "dat_validate = dat_train[filt==0,:]\n",
        "dat_train = dat_train[filt,:]\n",
        "\n",
        "dat_full = r.read().reshape(8,-1).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KXJ38evQPyk"
      },
      "source": [
        "Now that the data is nicely formatted, we can run our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9_I9HHxQ5B-"
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "clf.fit(dat_train[:,0:8],dat_train[:,8])\n",
        "\n",
        "landcover_prediction = clf.predict(dat_full)\n",
        "\n",
        "landcover_prediction_rast = landcover_prediction.reshape(r.read().shape[1],r.read().shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urb5QsMJ7IKU"
      },
      "source": [
        "Let's plot the data and see how they look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUNOgEmSqcP"
      },
      "source": [
        "fig,ax=plt.subplots()\n",
        "\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "cmap, norm = from_levels_and_colors([-0.5,0.5,1.5,2.5,3.5],['green','white','yellow','blue'])\n",
        "\n",
        "cax = ax.imshow(landcover_prediction_rast,cmap=cmap,norm=norm);\n",
        "cbar = fig.colorbar(cax,ticks=[0,1,2,3])\n",
        "cbar.ax.set_yticklabels(classes)  # vertically oriented colorbar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF-1WZrIjoIo"
      },
      "source": [
        "Now let's see how well we predict the different land use classes. We'll predict land cover on our validation dataset, which was held out of the training. Then, we'll make what is called a confusion matrix. A confusion matrix plots the actual land classification against the predicted land classification. Rows are true labels, and columns are predicted labels. If the model is perfect, then it will only have numbers in the diagonal components, meaning all cropland is predicted as cropland, etc., like this:\n",
        "\n",
        "```\n",
        "          cropland snow/ice urban water\n",
        "cropland    1000     0        0     0\n",
        "snow/ice      0     500       0     0\n",
        "urban         0      0       300    0\n",
        "water         0      0        0    200\n",
        "```\n",
        "Any numbers in the cells that are not on the diagonal mean there has been a mis-classification. We don't expect to have a perfect model, so some mis-classification is OK, but if most pixels are correctly classified, it means the model is doing pretty good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tUXjytl5MWM"
      },
      "source": [
        "landcover_prediction_validate = clf.predict(dat_validate[:,0:8])\n",
        "import pandas as pd\n",
        "\n",
        "C = confusion_matrix(dat_validate[:,8],landcover_prediction_validate)\n",
        "C_df = pd.DataFrame(C,columns = classes, index = classes)\n",
        "print(C_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-BORKBnjvaE"
      },
      "source": [
        "Let's look at the top row, showing predictions where the true land type is cropland. When this is the case, cropland is predicted 731 times, snow/ice 0 times, urban 14 times and water 0 times. So our model is pretty good at predicting cropland when the true label is cropland.\n",
        "\n",
        "Now look at the row that says urban. When the true label is urban, cropland is predicted 175 times, snow/ice 0 times, urban 71 times and water 0 times. So our model is good at classifying cropland as cropland, but often mis-classifies urban as cropland also. This is probably because many urban areas have significant vegetation, and thus looks similar to cropland. Once you identify problems like this, you can create new training data over the 'problem' areas, so the model can learn from them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLidTKOLV9cZ"
      },
      "source": [
        "###Part 2: Repeat this exercise, but with your own shapefile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KiJ04j4kDW2"
      },
      "source": [
        "Now we'll do the same thing with the shapefile that you created in Lab 10. Find the shapefile (there will be multiple files with the same name but different extensions). Click on the 'Files' tab on the left side of this window.\n",
        "\n",
        "Drag all of these files into the 'Files' tab in Google Colab. Then replace the shapefile_name variable below with the name of your shapefile, in quotes, with the .shp extension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm83TAmxkTFJ"
      },
      "source": [
        "shapefile_name = 'replace this with your shapefile name'\n",
        "shp=geopandas.read_file(shapefile_name)\n",
        "print(shp)\n",
        "\n",
        "fig,ax=plt.subplots()\n",
        "\n",
        "band = <enter band number here>\n",
        "\n",
        "plot_raster_band(r,band,ax)\n",
        "shp.plot(ax=ax,facecolor='none',edgecolor='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OajrvGJpkZSz"
      },
      "source": [
        "classes = np.unique(shp['Classname'])\n",
        "classvals = np.unique(shp['Classvalue'])\n",
        "print(classes)\n",
        "\n",
        "for kk in range(len(classes)):\n",
        "  class_ = classes[kk]\n",
        "  shp_filt=shp['Classname']==class_\n",
        "  print(shp[shp_filt])\n",
        "  r_mask,gtr=mask(r,shp['geometry'][shp_filt],crop=True,nodata=0)\n",
        "  if kk==0:\n",
        "    dat_train=r_mask.reshape(8,-1)\n",
        "    filt=dat_train[0,:]>0\n",
        "    dat_train=dat_train[:,filt].transpose()\n",
        "    dat_train=np.hstack((dat_train,kk*np.ones((dat_train.shape[0],1))))\n",
        "  else:\n",
        "    dat=r_mask.reshape(8,-1)\n",
        "    filt=dat[0,:]>0\n",
        "    dat=dat[:,filt].transpose()\n",
        "    dat=np.hstack((dat,kk*np.ones((dat.shape[0],1))))\n",
        "    dat_train=np.vstack((dat_train,dat))\n",
        "\n",
        "filt = np.random.uniform(size=(dat_train.shape[0]))>0.25 # make a filter that randomly selects 75% of the data\n",
        "\n",
        "dat_validate = dat_train[filt==0,:]\n",
        "dat_train = dat_train[filt,:]\n",
        "\n",
        "dat_full = r.read().reshape(8,-1).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRTsEYffkgNp"
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "clf.fit(dat_train[:,0:8],dat_train[:,8])\n",
        "\n",
        "landcover_prediction = clf.predict(dat_full)\n",
        "\n",
        "landcover_prediction_rast = landcover_prediction.reshape(r.read().shape[1],r.read().shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEtfO-IRkix0"
      },
      "source": [
        "fig,ax=plt.subplots()\n",
        "\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "vals = np.linspace(-0.5,len(classes)-0.5,len(classes)+1)\n",
        "colors = [ \"red\", \"blue\", \"green\", \"yellow\", \"purple\", \"orange\", \"white\", \"black\" ]\n",
        "cmap, norm = from_levels_and_colors(vals,colors[0:len(classes)])\n",
        "\n",
        "cax = ax.imshow(landcover_prediction_rast,cmap=cmap,norm=norm);\n",
        "cbar = fig.colorbar(cax,ticks=np.arange(0,len(classes)+1,1))\n",
        "cbar.ax.set_yticklabels(classes)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk0KYI_dj2y0"
      },
      "source": [
        "landcover_prediction_validate = clf.predict(dat_validate[:,0:8])\n",
        "\n",
        "C = confusion_matrix(dat_validate[:,8],landcover_prediction_validate)\n",
        "C_df = pd.DataFrame(C,columns = classes, index = classes)\n",
        "print(C_df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}